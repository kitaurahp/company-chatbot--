"""
ç¤¾å†…è¦å®šæ¤œç´¢ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ
Streamlit + Groq API + ChromaDBï¼ˆãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ï¼‰
"""
import os
import hashlib
import json
import streamlit as st
from dotenv import load_dotenv
from groq import Groq
from document_processor import DocumentProcessor
from vector_store import VectorStore

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ç¤¾å†…è¦å®šæ¤œç´¢ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ",
    page_icon="ğŸ“š",
    layout="wide"
)


def check_password():
    """ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰èªè¨¼ã‚’è¡Œã†"""

    def get_password():
        """ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å–å¾—ï¼ˆStreamlit Secrets ã¾ãŸã¯ ç’°å¢ƒå¤‰æ•°ï¼‰"""
        # Streamlit Secretsã‹ã‚‰å–å¾—ã‚’è©¦ã¿ã‚‹
        try:
            return st.secrets["APP_PASSWORD"]
        except (KeyError, FileNotFoundError):
            pass
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
        return os.getenv("APP_PASSWORD", "")

    correct_password = get_password()

    # ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯èªè¨¼ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç”¨ï¼‰
    if not correct_password:
        return True

    # æ—¢ã«ãƒ­ã‚°ã‚¤ãƒ³æ¸ˆã¿ã®å ´åˆ
    if st.session_state.get("authenticated", False):
        return True

    # ãƒ­ã‚°ã‚¤ãƒ³ç”»é¢ã‚’è¡¨ç¤º
    st.title("ğŸ” ç¤¾å†…è¦å®šæ¤œç´¢ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")
    st.markdown("---")
    st.markdown("ã“ã®ã‚¢ãƒ—ãƒªã¯ç¤¾å†…å°‚ç”¨ã§ã™ã€‚ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

    password = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password", key="password_input")

    if st.button("ãƒ­ã‚°ã‚¤ãƒ³", use_container_width=True):
        if password == correct_password:
            st.session_state.authenticated = True
            st.rerun()
        else:
            st.error("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“")

    return False

# CSSã§å…¥åŠ›æ¬„ã®ä½ç½®ã‚’èª¿æ•´
st.markdown("""
<style>
    /* ãƒãƒ£ãƒƒãƒˆå…¥åŠ›æ¬„ã‚’ç”»é¢å†…ã«è¡¨ç¤º */
    [data-testid="stBottom"] {
        bottom: 80px !important;
    }

    /* ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ã«ä¸‹éƒ¨ä½™ç™½ã‚’è¿½åŠ  */
    .main .block-container {
        padding-bottom: 150px;
    }
</style>
""", unsafe_allow_html=True)


def init_session_state():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–"""
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    if 'vector_store' not in st.session_state:
        st.session_state.vector_store = None
    if 'initialized' not in st.session_state:
        st.session_state.initialized = False


def initialize_vector_store():
    """ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®åˆæœŸåŒ–"""
    if st.session_state.vector_store is None:
        st.session_state.vector_store = VectorStore()
        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°è‡ªå‹•çš„ã«åˆæœŸåŒ–æ¸ˆã¿ã¨ã™ã‚‹
        if st.session_state.vector_store.get_collection_count() > 0:
            st.session_state.initialized = True


def load_documents():
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®èª­ã¿è¾¼ã¿ã¨ãƒ™ã‚¯ãƒˆãƒ«åŒ–"""
    with st.spinner("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã¿ä¸­..."):
        processor = DocumentProcessor(documents_dir="documents")
        documents = processor.process_all_documents()

        if not documents:
            st.warning("documentsãƒ•ã‚©ãƒ«ãƒ€å†…ã«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return False

        st.info(f"{len(documents)} ä»¶ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")

        # ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¦ä¿å­˜
        with st.spinner("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ä¸­..."):
            st.session_state.vector_store.add_documents(documents)

        st.success("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®èª­ã¿è¾¼ã¿ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        st.session_state.initialized = True
        return True


def expand_query(query: str) -> str:
    """
    ã‚¯ã‚¨ãƒªã‚’æ‹¡å¼µã—ã¦åŒç¾©èªã‚’å«ã‚ã‚‹

    Args:
        query: å…ƒã®ã‚¯ã‚¨ãƒª

    Returns:
        æ‹¡å¼µã•ã‚ŒãŸã‚¯ã‚¨ãƒª
    """
    # åŒç¾©èªãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆå¿…è¦ã«å¿œã˜ã¦è¿½åŠ å¯èƒ½ï¼‰
    synonyms = {
        "ä¼‘æš‡": ["ä¼‘æš‡", "ä¼‘æ¥­"],
        "ä¼‘æ¥­": ["ä¼‘æš‡", "ä¼‘æ¥­"],
        "å‹¤å‹™æ™‚é–“": ["å‹¤å‹™æ™‚é–“", "å§‹æ¥­", "çµ‚æ¥­", "åŠ´åƒæ™‚é–“"],
        "å§‹æ¥­": ["å§‹æ¥­", "å‹¤å‹™æ™‚é–“", "å‡ºå‹¤"],
        "çµ‚æ¥­": ["çµ‚æ¥­", "å‹¤å‹™æ™‚é–“", "é€€å‹¤"],
    }

    expanded_query = query
    for key, values in synonyms.items():
        if key in query:
            # å…ƒã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚€å…¨ã¦ã®åŒç¾©èªã‚’è¿½åŠ 
            for synonym in values:
                if synonym not in expanded_query:
                    expanded_query += f" {synonym}"

    return expanded_query


def get_cache_key(query: str, context_chunks: list) -> str:
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç”¨ã®ã‚­ãƒ¼ã‚’ç”Ÿæˆ"""
    content_hash = hashlib.md5(
        (query + str([c['content'][:100] for c in context_chunks])).encode()
    ).hexdigest()
    return content_hash


def generate_answer(query: str, context_chunks: list, model_name: str = "llama-3.3-70b-versatile") -> str:
    """
    Groq APIã‚’ä½¿ç”¨ã—ã¦å›ç­”ã‚’ç”Ÿæˆ

    Args:
        query: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•
        context_chunks: é–¢é€£ã™ã‚‹æ–‡æ›¸ãƒãƒ£ãƒ³ã‚¯
        model_name: ä½¿ç”¨ã™ã‚‹Groqãƒ¢ãƒ‡ãƒ«å

    Returns:
        ç”Ÿæˆã•ã‚ŒãŸå›ç­”
    """
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒã‚§ãƒƒã‚¯
    cache_key = get_cache_key(query, context_chunks)
    if 'response_cache' not in st.session_state:
        st.session_state.response_cache = {}

    if cache_key in st.session_state.response_cache:
        return st.session_state.response_cache[cache_key] + "\n\n_(ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—)_"

    # Groq APIã®è¨­å®šï¼ˆStreamlit Secrets ã¾ãŸã¯ ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼‰
    try:
        api_key = st.secrets["GROQ_API_KEY"]
    except (KeyError, FileNotFoundError):
        api_key = os.getenv("GROQ_API_KEY")

    if not api_key:
        return "ã‚¨ãƒ©ãƒ¼: GROQ_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"

    try:
        client = Groq(api_key=api_key)
    except Exception as e:
        return f"ã‚¨ãƒ©ãƒ¼: Groq APIã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚{str(e)}"

    # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆ
    context = "\n\n---\n\n".join([
        f"ã€{chunk['metadata']['filename']}ã€‘\n{chunk['content']}"
        for chunk in context_chunks
    ])

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½œæˆ
    prompt = f"""ã‚ãªãŸã¯ç¤¾å†…è¦å®šã«è©³ã—ã„ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®ç¤¾å†…è¦å®šã®æƒ…å ±ã‚’åŸºã«ã€è³ªå•ã«æ­£ç¢ºã«ç­”ãˆã¦ãã ã•ã„ã€‚

ã€ç¤¾å†…è¦å®šã®æƒ…å ±ã€‘
{context}

ã€è³ªå•ã€‘
{query}

ã€å›ç­”ã®æ³¨æ„äº‹é …ã€‘
- æä¾›ã•ã‚ŒãŸæƒ…å ±ã®ã¿ã‚’åŸºã«å›ç­”ã—ã¦ãã ã•ã„
- æƒ…å ±ã«ãªã„å†…å®¹ã¯ã€Œæä¾›ã•ã‚ŒãŸè¦å®šã«ã¯è¨˜è¼‰ãŒã‚ã‚Šã¾ã›ã‚“ã€ã¨å›ç­”ã—ã¦ãã ã•ã„
- å‹¤å‹™æ™‚é–“ãªã©ã®è¡¨ãƒ‡ãƒ¼ã‚¿ã¯ä»¥ä¸‹ã®å½¢å¼ã§ç°¡æ½”ã«è¡¨ç¤ºã—ã¦ãã ã•ã„ï¼š

  **æ—¥å‹¤**: 8:30ã€œ17:00ï¼ˆä¼‘æ†©1æ™‚é–“12åˆ†ï¼‰
  **é…ç•ª**: 10:30ã€œ19:00ï¼ˆä¼‘æ†©1æ™‚é–“12åˆ†ï¼‰
  **åœŸæ›œ**: 8:30ã€œ12:00ï¼ˆä¼‘æ†©ãªã—ï¼‰

- æ™‚åˆ»ã¯ã€Œ08:30:00ã€ã§ã¯ãªãã€Œ8:30ã€ã®ã‚ˆã†ã«ç°¡æ½”ã«è¡¨ç¤º
- ç®‡æ¡æ›¸ãã‚’ä½¿ã£ã¦è¦‹ã‚„ã™ãæ•´ç†ã—ã¦ãã ã•ã„

å›ç­”:"""

    try:
        # Groq APIã§å›ç­”ç”Ÿæˆ
        response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=2000
        )
        result = response.choices[0].message.content

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
        st.session_state.response_cache[cache_key] = result

        return result
    except Exception as e:
        return f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""

    # ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰èªè¨¼
    if not check_password():
        return

    init_session_state()

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.title("âš™ï¸ è¨­å®š")

        # Groqãƒ¢ãƒ‡ãƒ«é¸æŠ
        st.subheader("ğŸ¤– LLMãƒ¢ãƒ‡ãƒ«")
        model_name = st.selectbox(
            "ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«",
            ["llama-3.3-70b-versatile", "llama3-70b-8192", "mixtral-8x7b-32768"],
            help="Groq APIï¼ˆç„¡æ–™ãƒ»é«˜é€Ÿï¼‰"
        )
        st.info("ğŸ” æ¤œç´¢: ãƒ­ãƒ¼ã‚«ãƒ«ï¼ˆç„¡æ–™ï¼‰\nğŸ¤– å›ç­”: Groq APIï¼ˆé«˜ç²¾åº¦ãƒ»ç„¡æ–™ï¼‰")

        # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰
        debug_mode = st.checkbox("ğŸ” ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ï¼ˆæ¤œç´¢çµæœã‚’è¡¨ç¤ºï¼‰", value=False)

        # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’åˆæœŸåŒ–
        initialize_vector_store()

        st.divider()

        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç®¡ç†
        st.subheader("ğŸ“„ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç®¡ç†")

        if st.session_state.vector_store:
            doc_count = st.session_state.vector_store.get_collection_count()
            st.info(f"ç™»éŒ²æ¸ˆã¿ãƒãƒ£ãƒ³ã‚¯æ•°: {doc_count}")

        if st.button("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã‚€", use_container_width=True):
            load_documents()

        if st.button("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚¯ãƒªã‚¢", use_container_width=True):
            if st.session_state.vector_store:
                st.session_state.vector_store.clear_collection()
                st.session_state.initialized = False
                st.success("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")

        if st.button("ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢", use_container_width=True):
            st.session_state.messages = []
            st.success("ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
            st.rerun()

        st.divider()

        # ä½¿ã„æ–¹
        st.subheader("ğŸ“– ä½¿ã„æ–¹")
        st.markdown("""
        1. `documents` ãƒ•ã‚©ãƒ«ãƒ€ã«PDF/Word/Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®
        2. ã€Œãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã‚€ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
        3. ãƒãƒ£ãƒƒãƒˆç”»é¢ã§è³ªå•ã‚’å…¥åŠ›

        **âœ¨ ç‰¹å¾´:**
        - æ¤œç´¢ã¯ãƒ­ãƒ¼ã‚«ãƒ«ï¼ˆç„¡æ–™ãƒ»é«˜é€Ÿï¼‰
        - å›ç­”ç”Ÿæˆã¯Gemini APIï¼ˆé«˜ç²¾åº¦ï¼‰
        - ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã§åŒã˜è³ªå•ã¯å†åˆ©ç”¨
        """)

    # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
    st.title("ğŸ“š ç¤¾å†…è¦å®šæ¤œç´¢ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")
    st.caption("ğŸ” ãƒ­ãƒ¼ã‚«ãƒ«æ¤œç´¢ + ğŸ¤– Groq APIï¼ˆé«˜ç²¾åº¦ãƒ»ç„¡æ–™ï¼‰")

    if not st.session_state.initialized:
        st.info("å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ã€Œãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã‚€ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ç™»éŒ²ã—ã¦ãã ã•ã„")
        return

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

            # å‚ç…§è³‡æ–™ã®è¡¨ç¤º
            if message["role"] == "assistant" and "sources" in message:
                # é‡è¤‡ã‚’é™¤ã„ã¦ãƒ•ã‚¡ã‚¤ãƒ«åã®ã¿è¡¨ç¤º
                unique_files = list(set([source['filename'] for source in message["sources"]]))
                if unique_files:
                    st.caption("ğŸ“š å‚è€ƒè³‡æ–™: " + " / ".join(unique_files))

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
    if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šæœ‰çµ¦ä¼‘æš‡ã®ç”³è«‹æ–¹æ³•ã¯ï¼Ÿï¼‰"):
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å›ç­”ã‚’ç”Ÿæˆ
        with st.chat_message("assistant"):
            with st.spinner("æ¤œç´¢ä¸­..."):
                # ã‚¯ã‚¨ãƒªã‚’æ‹¡å¼µï¼ˆåŒç¾©èªã‚’å«ã‚ã‚‹ï¼‰
                expanded_prompt = expand_query(prompt)

                # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ï¼ˆãƒ™ã‚¯ãƒˆãƒ« + ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼‰
                search_results = st.session_state.vector_store.search(expanded_prompt, n_results=15)

                # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ï¼šæ¤œç´¢çµæœã‚’è¡¨ç¤º
                if debug_mode and search_results:
                    with st.expander("ğŸ” æ¤œç´¢çµæœã®è©³ç´°", expanded=True):
                        st.write(f"**æ‹¡å¼µã‚¯ã‚¨ãƒª:** {expanded_prompt}")
                        st.write(f"**æ¤œç´¢çµæœæ•°:** {len(search_results)}")
                        for i, result in enumerate(search_results, 1):
                            st.markdown(f"**{i}. {result['metadata']['filename']}** (è·é›¢: {result['distance']:.3f})")
                            st.text(result['content'][:300] + "...")
                            st.divider()

                if not search_results:
                    response = "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚é–¢é€£ã™ã‚‹æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
                    st.markdown(response)
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": response
                    })
                else:
                    # å›ç­”ã‚’ç”Ÿæˆ
                    with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­..."):
                        response = generate_answer(prompt, search_results, model_name)
                        st.markdown(response)

                    # å‚ç…§è³‡æ–™ã‚’è¡¨ç¤ºï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã®ã¿ã€é‡è¤‡é™¤å¤–ï¼‰
                    unique_files = list(set([r['metadata']['filename'] for r in search_results]))
                    if unique_files:
                        st.caption("ğŸ“š å‚è€ƒè³‡æ–™: " + " / ".join(unique_files))

                    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿å­˜
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": response,
                        "sources": [
                            {
                                "filename": r['metadata']['filename'],
                                "chunk_index": r['metadata']['chunk_index'],
                                "total_chunks": r['metadata']['total_chunks'],
                                "content": r['content']
                            }
                            for r in search_results
                        ]
                    })


if __name__ == "__main__":
    main()
